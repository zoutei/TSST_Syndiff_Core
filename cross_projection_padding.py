"""
Cross-Projection Padding Module for PS1 Sliding Window Pipeline

This module handles the complex task of applying padding across projection boundaries.
It uses metadata generated by `pancakes_v2.py` (via CSV) to identify required padding skycells,
optimized by loading each skycell only once even if needed by multiple rows (current/next).

Key features:
-   Optimized `PaddingJob` scheduling to deduplicate loads.
-   Localized WCS creation (`create_padding_wcs`) for accurate reprojection.
-   Edge artifact suppression (`exclude_edge_pixels`).
"""

import logging
from dataclasses import dataclass, field
from typing import List, Tuple, Dict, Optional

import numpy as np
import pandas as pd
from astropy.wcs import WCS
from reproject import reproject_interp

from csv_utils import load_csv_data
from zarr_utils import load_skycell_bands_masks_and_headers
from band_utils import process_skycell_bands

logger = logging.getLogger(__name__)

# Constants (Must match process_ps1.py)
PAD_SIZE = 480
CELL_OVERLAP = 480
EDGE_EXCLUSION = 10


@dataclass
class SkycellPaddingInfo:
    """Information about a single padding requirement for a specific skycell."""
    skycell_name: str
    projection: str
    locations: List[str]  # e.g., ["top", "top_left"]
    cell_position: str    # "first", "last", "interior"
    row_position: str     # "top", "bottom", "middle"
    actual_index: int     # Index in the row


@dataclass
class PaddingJob:
    """
    A unit of work: one skycell to be loaded and applied to one or more targets.
    
    Attributes:
        skycell_name: Name of the skycell to load (e.g., "skycell.2556.080")
        source_projection: Projection ID of the source skycell
        targets: List of (target_array, locations) tuples. 
                 target_array is the destination (current or next array).
                 locations is a list of strings (e.g., ["bottom"]) for that target.
    """
    skycell_name: str
    source_projection: str
    targets: List[Tuple[np.ndarray, List[str]]] = field(default_factory=list)


# --- Helper Functions (Ported from Notebook & modern_padding) ---

def determine_row_position(row_id: int, all_row_ids: List[int]) -> str:
    """Determine if row is top, bottom, or middle row in projection."""
    if row_id == min(all_row_ids):
        return "bottom"
    elif row_id == max(all_row_ids):
        return "top"
    else:
        return "middle"


def analyze_cell_positions(row_cells: List[str]) -> Dict[str, str]:
    """Analyze position of each cell within its actual row."""
    positions = {}
    actual_row_size = len(row_cells)

    for i, cell_name in enumerate(row_cells):
        if i == 0:
            position_type = "first"
        elif i == actual_row_size - 1:
            position_type = "last"
        else:
            position_type = "interior"
        positions[cell_name] = position_type
    return positions



def _get_cd_matrix(row: pd.Series) -> List[List[float]]:
    """Helper to extract CD matrix from row, handling CD vs CDELT/PC."""
    # Try explicit CD matrix first
    if "CD1_1" in row:
        return [
            [float(row.get(f"CD{i}_{j}", 0.0)) for j in [1, 2]] 
            for i in [1, 2]
        ]
    
    # Try CDELT + PC
    # Default PC is identity if missing, but usually present if CDELT is present
    if "CDELT1" in row:
        cdelt = [float(row.get(f"CDELT{i}", 1.0)) for i in [1, 2]]
        pc = [
            [float(row.get(f"PC{i}_{j}", 0.0 if i != j else 1.0)) for j in [1, 2]]
            for i in [1, 2]
        ]
        # CD_ij = CDELT_i * PC_ij
        cd = [
            [cdelt[i-1] * pc[i-1][j-1] for j in [1, 2]]
            for i in [1, 2]
        ]
        return cd

    # Fallback to default (approx 1 arcsec/pixel, flipped RA)
    return [[-1.0/3600, 0.0], [0.0, 1.0/3600]]


def create_cell_wcs(cell_name: str, metadata: dict) -> WCS:
    """Create WCS object for a specific cell from metadata."""
    proj_df = metadata["dataframe"]
    cell_row = proj_df[proj_df["NAME"] == cell_name]

    if cell_row.empty:
        raise ValueError(f"Cell {cell_name} not found in metadata")

    cell_data = cell_row.iloc[0]

    # Extract WCS parameters
    crval = [float(cell_data.get(f"CRVAL{i}", 0.0)) for i in [1, 2]]
    crpix = [float(cell_data.get(f"CRPIX{i}", 0.0)) for i in [1, 2]]
    
    cd = _get_cd_matrix(cell_data)

    wcs = WCS(naxis=2)
    wcs.wcs.crval = crval
    wcs.wcs.crpix = crpix
    wcs.wcs.cd = cd
    wcs.wcs.ctype = ["RA---TAN", "DEC--TAN"]
    wcs.wcs.cunit = ["deg", "deg"]
    return wcs


def create_padding_wcs(master_wcs: WCS, config, location: str, cell_index: int) -> Tuple[WCS, Tuple[int, int], Tuple[float, float]]:
    """
    Create a localized WCS centered at the padding region for reprojection.
    Ported from notebook code for better accuracy than global master WCS.
    """
    cell_width = config.cell_width
    cell_height = config.cell_height

    # Cell boundaries in master array (for top/bottom padding)
    cell_x_start = PAD_SIZE + cell_index * (config.cell_width - CELL_OVERLAP)
    cell_x_center = cell_x_start + cell_width / 2
    
    # Calculate key Y coordinates
    cell_y_top = PAD_SIZE + cell_height + (PAD_SIZE - EDGE_EXCLUSION) / 2
    cell_y_bottom = (PAD_SIZE + EDGE_EXCLUSION) / 2
    cell_y_center = PAD_SIZE + cell_height / 2
    
    # Calculate key X coordinates
    cell_x_left = cell_x_start - (PAD_SIZE - EDGE_EXCLUSION) / 2
    cell_x_right = cell_x_start + cell_width + (PAD_SIZE - EDGE_EXCLUSION) / 2

    pad_size_adjusted = PAD_SIZE + EDGE_EXCLUSION

    # Defaults
    padding_x_center = cell_x_center
    padding_y_center = cell_y_center
    padding_width = pad_size_adjusted
    padding_height = pad_size_adjusted

    # Adjust based on location
    if "top" in location:
        padding_y_center = cell_y_top
        padding_width = config.cell_width
    if "bottom" in location:
        padding_y_center = cell_y_bottom
        padding_width = config.cell_width
    if "left" in location:
        padding_x_center = cell_x_left
        padding_height = config.cell_height
    if "right" in location:
        padding_x_center = cell_x_right
        padding_height = config.cell_height

    # Convert padding center to world coordinates using master WCS
    padding_center_world = master_wcs.pixel_to_world(padding_x_center, padding_y_center)

    # Create new WCS centered at the padding region
    padding_wcs = WCS(naxis=2)
    padding_wcs.wcs.crpix = [padding_width / 2, padding_height / 2]
    padding_wcs.wcs.crval = [padding_center_world.ra.degree, padding_center_world.dec.degree]
    padding_wcs.wcs.ctype = master_wcs.wcs.ctype
    if master_wcs.wcs.has_cd():
        padding_wcs.wcs.cd = master_wcs.wcs.cd.copy()
    else:
        padding_wcs.wcs.pc = master_wcs.wcs.pc.copy()
        padding_wcs.wcs.cdelt = master_wcs.wcs.cdelt.copy()
    
    return padding_wcs, (int(padding_height), int(padding_width)), (padding_y_center, padding_x_center)


def exclude_edge_pixels(data: np.ndarray, edge_width: int = 10) -> np.ndarray:
    """Replace edge pixels with NaN to avoid edge artifacts during reprojection."""
    cleaned = data.copy()
    cleaned[:edge_width, :] = np.nan
    cleaned[-edge_width:, :] = np.nan
    cleaned[:, :edge_width] = np.nan
    cleaned[:, -edge_width:] = np.nan
    return cleaned


def determine_cell_position_from_skycell(main_skycell: str, metadata: dict) -> Tuple[int, int]:
    """Find the (row_index, cell_index) for a given skycell name in the metadata."""
    # Note: row_index here is just the index in the sorted list of rows, not the row_id
    sorted_row_ids = sorted(metadata["rows"].keys())
    
    for r_idx, row_id in enumerate(sorted_row_ids):
        cells = metadata["rows"][row_id]
        for c_idx, (cell_name, _) in enumerate(cells):
            if cell_name == main_skycell:
                return r_idx, c_idx
    return -1, -1


def get_cell_index_in_row(row_id: int, cell_name: str, metadata: dict) -> int:
    """Get the 0-based index of a cell within a specific row."""
    if row_id not in metadata["rows"]:
        return -1
    cells = metadata["rows"][row_id]
    for i, (name, _) in enumerate(cells):
        if name == cell_name:
            return i
    return -1


def create_master_array_wcs(metadata: dict, config, current_row_id: int) -> WCS:
    """Create WCS object for the master array based on first cell + padding offset."""
    # Get first cell's WCS information from the dataframe
    # Note: metadata["dataframe"] already contains only rows for the correct projection
    proj_df = metadata["dataframe"]
    proj_df = proj_df[proj_df["y"] == current_row_id]

    if proj_df.empty:
        raise ValueError(f"No data found for projection {metadata['projection']} and row {current_row_id}")

    proj_df = proj_df.sort_values(by=["x"])
    first_cell = proj_df.iloc[0]

    # Extract WCS parameters
    crval1 = float(first_cell.get("CRVAL1", 0.0))
    crval2 = float(first_cell.get("CRVAL2", 0.0))
    crpix1 = float(first_cell.get("CRPIX1", 0.0))
    crpix2 = float(first_cell.get("CRPIX2", 0.0))
    
    cd = _get_cd_matrix(first_cell)

    # Create WCS object
    master_wcs = WCS(naxis=2)
    master_wcs.wcs.crval = [crval1, crval2]
    master_wcs.wcs.crpix = [crpix1 + PAD_SIZE, crpix2 + PAD_SIZE]  # Adjust for padding
    master_wcs.wcs.cd = cd
    master_wcs.wcs.ctype = ["RA---TAN", "DEC--TAN"]
    master_wcs.wcs.cunit = ["deg", "deg"]

    return master_wcs


# --- Core Logic ---

def parse_row_padding_requirements(metadata: dict, csv_path: str, row_id: int, all_row_ids: List[int]) -> Dict[str, SkycellPaddingInfo]:
    """
    Parse the CSV to find all cross-projection padding requirements for a specific row.
    Returns a dict mapping padding_skycell_name -> SkycellPaddingInfo.
    """
    df = load_csv_data(csv_path)
    current_projection = metadata["projection"]
    
    # Get cells for this row
    if row_id not in metadata["rows"]:
        return {}
    
    # metadata["rows"][row_id] is a list of (cell_name, x_coord) tuples
    row_cells = [c[0] for c in metadata["rows"][row_id]]
    
    # Determine context
    row_position = determine_row_position(row_id, all_row_ids)
    cell_positions = analyze_cell_positions(row_cells)
    
    # Filter CSV for this row
    proj_df = df[df["projection"].astype(str) == str(current_projection)]
    row_df = proj_df[proj_df["y"] == row_id]
    
    requirements = {}
    
    padding_cols = [
        "pad_skycell_top", "pad_skycell_bottom", 
        "pad_skycell_left", "pad_skycell_right", 
        "pad_skycell_top_left", "pad_skycell_top_right", 
        "pad_skycell_bottom_left", "pad_skycell_bottom_right"
    ]
    
    for _, row_data in row_df.iterrows():
        main_cell_name = row_data["NAME"]
        if main_cell_name not in row_cells:
            continue
            
        cell_info_type = cell_positions.get(main_cell_name, "interior")
        
        for col in padding_cols:
            val = row_data.get(col)
            if pd.isna(val) or not str(val).strip():
                continue
                
            # Handle possible multiple cells (slash separated - rare but possible)
            padding_cells = [c.strip() for c in str(val).split("/") if c.strip()]
            location = col.replace("pad_skycell_", "")
            
            for p_cell in padding_cells:
                # Check if cross-projection
                try:
                    p_proj = p_cell.split(".")[1]
                except IndexError:
                    continue
                    
                if p_proj == str(current_projection):
                    continue # Skip intra-projection padding
                
                # Apply Filtering Logic (defensive check)
                # Only trust the CSV if it makes geometric sense
                # e.g. don't apply "top" padding if we aren't at the top row
                
                valid = True
                if "top" in location and row_position != "top":
                    valid = False
                if "bottom" in location and row_position != "bottom":
                    valid = False
                if "left" in location and cell_info_type != "first":
                    valid = False
                if "right" in location and cell_info_type != "last":
                    valid = False
                
                if not valid:
                    logger.debug(f"Skipping {location} padding {p_cell} for {main_cell_name} (filtered)")
                    continue
                
                # Register
                if p_cell not in requirements:
                    requirements[p_cell] = SkycellPaddingInfo(
                        skycell_name=p_cell,
                        projection=p_proj,
                        locations=[],
                        cell_position=cell_info_type,
                        row_position=row_position,
                        actual_index=row_cells.index(main_cell_name)
                    )
                requirements[p_cell].locations.append(location)

    return requirements


def analyze_padding_jobs(
    current_reqs: Dict[str, SkycellPaddingInfo], 
    next_reqs: Dict[str, SkycellPaddingInfo],
    current_array: np.ndarray,
    next_array: np.ndarray
) -> List[PaddingJob]:
    """
    Consolidate requirements from current and next rows into a unique list of jobs.
    If a skycell is needed by both, one job handles both targets to avoid double loading.
    """
    jobs = {}
    
    # Process Current Row Requirements
    for name, info in current_reqs.items():
        if name not in jobs:
            jobs[name] = PaddingJob(name, info.projection)
        jobs[name].targets.append((current_array, info.locations))
        
    # Process Next Row Requirements
    for name, info in next_reqs.items():
        if name not in jobs:
            jobs[name] = PaddingJob(name, info.projection)
        jobs[name].targets.append((next_array, info.locations))
        
    return list(jobs.values())


from concurrent.futures import ThreadPoolExecutor
from threading import Lock
import time

def _process_padding_job(job, state, config, metadata, master_wcs, master_wcs_next, zarr_path, current_df, current_reqs, next_reqs, write_lock):
    """Helper to process a single padding job."""
    try:
        start_time = time.time()
        # A. Load Source Data
        parts = job.skycell_name.split(".")
        if len(parts) != 3:
            logger.warning(f"Invalid padding skycell name: {job.skycell_name}")
            return False

        source_skycell_id = parts[2]
        source_proj = job.source_projection

        # Load from Zarr
        import zarr
        try:
            store = zarr.open(zarr_path, mode='r')
            bands, masks, weights, headers, headers_weight = load_skycell_bands_masks_and_headers(store, source_proj, source_skycell_id)
        except Exception as e:
            logger.error(f"Failed to open/load from zarr store at {zarr_path}: {e}")
            return False

        if bands is None:
            logger.warning(f"Failed to load padding data for {job.skycell_name}")
            return False

        # Process to Image
        data, mask, _ = process_skycell_bands(bands, masks, weights, headers, headers_weight)

        # Mask Edges
        data = exclude_edge_pixels(data, EDGE_EXCLUSION)

        # Create Source WCS
        source_metadata = {"dataframe": current_df}
        try:
            source_wcs = create_cell_wcs(job.skycell_name, source_metadata)
        except ValueError:
            logger.warning(f"Could not create WCS for {job.skycell_name}")
            return False

        # B. Apply to Targets
        for target_array, locations in job.targets:
            # Re-find the requirement info
            active_reqs = current_reqs if target_array is state.current_array else next_reqs
            
            # Select correct WCS
            if target_array is state.current_array:
                active_wcs = master_wcs
            else:
                active_wcs = master_wcs_next

            if active_wcs is None:
                logger.error(f"Active WCS is None for target! Job: {job.skycell_name}")
                continue

            if job.skycell_name not in active_reqs:
                continue 

            req_info = active_reqs[job.skycell_name]
            cell_index = req_info.actual_index

            for loc in locations:
                # Create Localized Target WCS using ACTIVE WCS
                target_wcs, target_shape, (y_center, x_center) = create_padding_wcs(
                    active_wcs, config, loc, cell_index
                )

                # Reproject (Expensive, run concurrently)
                reprojected, footprint = reproject_interp(
                    (data, source_wcs),
                    target_wcs,
                    shape_out=target_shape,
                    order="bilinear"
                )

                # Calculate placement coordinates
                h, w = target_shape
                y_start = int(y_center - h / 2)
                y_end = int(y_start + h)
                x_start = int(x_center - w / 2)
                x_end = int(x_start + w)
                
                # Bounds check
                if y_start < 0 or x_start < 0 or y_end > target_array.shape[0] or x_end > target_array.shape[1]:
                    logger.warning(f"Padding out of bounds for {job.skycell_name} at {loc}")
                    continue

                # Stitch - thread safe write with lock
                valid_mask = (~np.isnan(reprojected)) & (footprint > 0)

                if np.any(valid_mask):
                    with write_lock:
                        target_slice = target_array[y_start:y_end, x_start:x_end]
                        target_slice[valid_mask] = reprojected[valid_mask]

        elapsed = time.time() - start_time
        logger.info(f"Job {job.skycell_name} finished in {elapsed:.2f}s")
        return True

    except Exception as e:
        logger.error(f"Failed to process padding job {job.skycell_name}: {e}", exc_info=True)
        return False


def apply_cross_projection_padding(
    state, 
    config, 
    metadata: dict, 
    current_row_id: int, 
    next_row_id: Optional[int], 
    zarr_path: str, 
    csv_path: str
):
    """
    Main entry point for applying cross-projection padding.
    Parallelized version.
    """
    # 1. Gather Requirements
    try:
        current_df = load_csv_data(csv_path)
    except Exception as e:
         logger.warning(f"Failed to load CSV {csv_path}: {e}")
         return

    proj_df = current_df[current_df["projection"].astype(str) == str(metadata["projection"])]
    all_row_ids = sorted(proj_df["y"].unique())
    
    current_reqs = parse_row_padding_requirements(metadata, csv_path, current_row_id, all_row_ids)
    next_reqs = {}
    if next_row_id is not None:
        next_reqs = parse_row_padding_requirements(metadata, csv_path, next_row_id, all_row_ids)
        
    if not current_reqs and not next_reqs:
        return

    logger.info(f"[CrossPadding] Found {len(current_reqs)} reqs for current, {len(next_reqs)} for next.")
    
    # 2. Create Jobs (Deduplicated)
    jobs = analyze_padding_jobs(current_reqs, next_reqs, state.current_array, state.next_array)

    if not jobs:
        return

    # 3. Create Master WCS for Current Row (Used as reference base)
    master_wcs = create_master_array_wcs(metadata, config, current_row_id) 
    
    master_wcs_next = None
    if next_row_id is not None:
         master_wcs_next = create_master_array_wcs(metadata, config, next_row_id) 

    # 4. Execute Jobs in Parallel
    write_lock = Lock()
    num_workers = min(len(jobs), 8) # Limit parallelism sensibly
    
    logger.info(f"[CrossPadding] Starting {len(jobs)} jobs with {num_workers} threads.")
    
    successful_jobs = 0
    with ThreadPoolExecutor(max_workers=num_workers) as executor:
        futures = []
        for job in jobs:
            future = executor.submit(
                _process_padding_job,
                job, state, config, metadata, master_wcs, master_wcs_next, zarr_path, current_df, current_reqs, next_reqs, write_lock
            )
            futures.append(future)
            
        for future in futures:
            try:
                if future.result():
                    successful_jobs += 1
            except Exception as e:
                logger.error(f"Job future failed: {e}")

    logger.info(f"[CrossPadding] Applied {successful_jobs}/{len(jobs)} padding jobs.")
